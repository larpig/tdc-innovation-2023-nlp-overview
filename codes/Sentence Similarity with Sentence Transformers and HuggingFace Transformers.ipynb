{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMbhKqLZb7vdGbjs6ozYPuR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **[Hugging Face: Sentence Similarity](https://huggingface.co/tasks/sentence-similarity)**\n","\n"],"metadata":{"id":"bEs70VI56t3t"}},{"cell_type":"markdown","source":["## **Sentence Similarity**\n","\n","Sentence Similarity is the task of determining how similar two texts are. Sentence similarity models convert input texts into vectors (embeddings) that capture semantic information and calculate how close (similar) they are between them. This task is particularly useful for information retrieval and clustering/grouping.\n","\n","### **Use Cases**\n","\n","**Information Retrieval**\n","\n","You can extract information from documents using Sentence Similarity models. The first step is to rank documents using Passage Ranking models. You can then get to the top ranked document and search it with Sentence Similarity models by selecting the sentence that has the most similarity to the input query.\n","\n","### **The Sentence Transformers library**\n","\n","\n","The [Sentence Transformers](https://www.sbert.net/) library is very powerful for calculating embeddings of sentences, paragraphs, and entire documents. An embedding is just a vector representation of a text and is useful for finding how similar two texts are.\n","\n","You can find and use [hundreds of Sentence Transformers](https://huggingface.co/models?library=sentence-transformers&sort=downloads) models from the Hub by directly using the library, playing with the widgets in the browser or using the Inference API."],"metadata":{"id":"Owpvqfm6_Ejz"}},{"cell_type":"markdown","source":["### **Example**"],"metadata":{"id":"EdwC0CkA_1zl"}},{"cell_type":"code","source":["!pip install -U sentence-transformers --quiet"],"metadata":{"id":"UQy3b_q-0SHz","executionInfo":{"status":"ok","timestamp":1686664157530,"user_tz":-60,"elapsed":20660,"user":{"displayName":"Luis Antonio Rodrigues","userId":"07263425132269744262"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1d8dc2ff-bd35-40ca-fcd5-3ac7566b5cee"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/86.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m97.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}]},{"cell_type":"code","source":["# Download used models\n","!git clone https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n","#!git clone https://huggingface.co/sentence-transformers/distiluse-base-multilingual-cased-v2"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-xcQV23-PbEj","executionInfo":{"status":"ok","timestamp":1686664164072,"user_tz":-60,"elapsed":6549,"user":{"displayName":"Luis Antonio Rodrigues","userId":"07263425132269744262"}},"outputId":"9f6ab1cb-73d7-499e-f6bc-b6811dcf2560"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'all-MiniLM-L6-v2'...\n","remote: Enumerating objects: 46, done.\u001b[K\n","remote: Counting objects: 100% (21/21), done.\u001b[K\n","remote: Compressing objects: 100% (11/11), done.\u001b[K\n","remote: Total 46 (delta 10), reused 21 (delta 10), pack-reused 25\u001b[K\n","Unpacking objects: 100% (46/46), 314.94 KiB | 1.92 MiB/s, done.\n","Filtering content: 100% (3/3), 260.15 MiB | 44.32 MiB/s, done.\n"]}]},{"cell_type":"code","source":["from sentence_transformers import SentenceTransformer, util\n","\n","model_name = 'sentence-transformers/all-MiniLM-L6-v2' # EN (384 dimensions)\n","#model_name = 'distiluse-base-multilingual-cased-v2' # multilingual (512 dimensions) (Pooling + Dense)\n","model = SentenceTransformer(model_name)\n","\n","sentences = [\"what is happiness?\", \"Happiness is a state of the spirit.\"]\n","embeddings = model.encode(sentences)\n","\n","similarity = util.pytorch_cos_sim(embeddings[0], embeddings[1]).numpy()[0][0]\n","print(similarity)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"spo4xmkz6u_U","executionInfo":{"status":"ok","timestamp":1686664765044,"user_tz":-60,"elapsed":1286,"user":{"displayName":"Luis Antonio Rodrigues","userId":"07263425132269744262"}},"outputId":"e9d14280-e87e-432b-fc85-20130dc43304"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["0.7928971\n"]}]},{"cell_type":"markdown","source":["### **Additional Resources**\n","- [SBert | Sentence Transformers Documentation](https://www.sbert.net/)\n","- [Hugging Face | Getting Started With Embeddings](https://huggingface.co/blog/getting-started-with-embeddings)\n","- [Hugging Face | Sentence Transformers in the Hugging Face Hub](https://huggingface.co/blog/sentence-transformers-in-the-hub)\n","- [Hugging Face | Using Sentence Transformers at Hugging Face](https://huggingface.co/docs/hub/sentence-transformers)\n","- [Hugging Face | Models for Sentence Similarity](https://huggingface.co/models?library=sentence-transformers&sort=downloads)\n","- [Hugging Face | Models for Sentence Similarity in Portuguese](https://huggingface.co/models?library=sentence-transformers&language=pt&sort=downloads)"],"metadata":{"id":"5FrML-t47TVs"}},{"cell_type":"markdown","source":["### **Example in Portuguese**"],"metadata":{"id":"2-304AHc7ydr"}},{"cell_type":"code","source":["# Download used models\n","!git clone https://huggingface.co/rufimelo/bert-large-portuguese-cased-sts\n","#!git clone https://huggingface.co/ricardoz/BERTugues-base-portuguese-cased\n","#!git clone https://huggingface.co/PORTULAN/albertina-ptpt"],"metadata":{"id":"bC0oxfpO1eMW","executionInfo":{"status":"ok","timestamp":1686664261600,"user_tz":-60,"elapsed":16683,"user":{"displayName":"Luis Antonio Rodrigues","userId":"07263425132269744262"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7b9ad2c2-1b69-4d34-af68-df9d3713b7b2"},"execution_count":8,"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Cloning into 'bert-large-portuguese-cased-sts'...\n","remote: Enumerating objects: 34, done.\u001b[K\n","remote: Total 34 (delta 0), reused 0 (delta 0), pack-reused 34\u001b[K\n","Unpacking objects: 100% (34/34), 289.16 KiB | 2.05 MiB/s, done.\n"]}]},{"cell_type":"code","source":["from sentence_transformers import SentenceTransformer, util\n","\n","model_name = 'rufimelo/bert-large-portuguese-cased-sts' # PT-BR (1024 dimensions)\n","#model_name = 'ricardoz/BERTugues-base-portuguese-cased' # PT-BR (768 dimensions)\n","#model_name = 'PORTULAN/albertina-ptpt' # PT-PT (1536 dimensions)\n","model = SentenceTransformer(model_name)\n","\n","sentences = [\"Tinha uma pedra no meio do caminho.\", \"Mas essa pedra não era o Português.\"]\n","sentence_embeddings = model.encode(sentences)\n","\n","print(\"Sentence embeddings:\")\n","print(sentence_embeddings)\n","\n","sentence_similarity = util.pytorch_cos_sim(sentence_embeddings[0], sentence_embeddings[1]).numpy()[0][0]\n","\n","print(\"Sentence similarity:\")\n","print(sentence_similarity)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GsyZrH8v4CX0","executionInfo":{"status":"ok","timestamp":1686664332237,"user_tz":-60,"elapsed":7520,"user":{"displayName":"Luis Antonio Rodrigues","userId":"07263425132269744262"}},"outputId":"242d4567-6961-47c6-ca3d-41eab16650c0"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Sentence embeddings:\n","[[ 1.7217176  -0.48384118  0.06242486 ...  0.49255776 -1.1902417\n","   0.9546114 ]\n"," [ 0.05113917 -0.9153737  -0.1231728  ...  0.7539909  -0.73372877\n","   1.6433395 ]]\n","Sentence similarity:\n","0.4097103\n"]}]},{"cell_type":"markdown","source":["## **Using HuggingFace Transformers**"],"metadata":{"id":"0dsgeejqZOB6"}},{"cell_type":"code","source":["!pip install -U transformers --quiet\n","!pip install -U torch --quiet"],"metadata":{"id":"yn7d1Z58aieo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModel\n","import torch\n","\n","#Mean Pooling - Take attention mask into account for correct averaging\n","def mean_pooling(model_output, attention_mask):\n","    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n","    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n","    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n","\n","# Sentences we want sentence embeddings for\n","sentences = ['This is an example sentence', 'Each sentence is converted']\n","\n","# Load model from HuggingFace Hub\n","model_name = 'rufimelo/bert-large-portuguese-cased-sts'\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModel.from_pretrained(model_name)\n","\n","# Tokenize sentences\n","encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n","\n","# Compute token embeddings\n","with torch.no_grad():\n","    model_output = model(**encoded_input)\n","\n","# Perform pooling. In this case, mean pooling.\n","sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n","\n","print(\"Sentence embeddings:\")\n","print(sentence_embeddings)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nTsrRjXIYDod","executionInfo":{"status":"ok","timestamp":1685553466042,"user_tz":-60,"elapsed":8153,"user":{"displayName":"Luis Antonio Rodrigues","userId":"07263425132269744262"}},"outputId":"262d63b7-364f-4062-d195-8d497a69e726"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"]},{"output_type":"stream","name":"stdout","text":["Sentence embeddings:\n","tensor([[ 0.7264, -1.6596, -0.7420,  ...,  0.0246, -1.2221,  0.5228],\n","        [ 0.0238, -0.9716, -0.1902,  ..., -0.3143, -0.1059,  0.1850]])\n"]}]},{"cell_type":"code","source":["# Another option for the sentece embedding according to original BERT paper\n","\n","sentence_embeddings =  model(**encoded_input).last_hidden_state[:, 0]\n","\n","print(\"Sentence embeddings based on [CLS] token:\")\n","print(sentence_embeddings)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OuhYauhHeVFn","executionInfo":{"status":"ok","timestamp":1685553445791,"user_tz":-60,"elapsed":618,"user":{"displayName":"Luis Antonio Rodrigues","userId":"07263425132269744262"}},"outputId":"4f18a231-1095-4982-c672-995b7df78f12"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sentence embeddings based on [CLS] token:\n","tensor([[ 0.4050, -1.5686, -1.1648,  ..., -0.0514, -1.4019,  0.2716],\n","        [-0.2752, -0.5248, -0.8590,  ..., -0.4845, -0.2114, -0.5468]],\n","       grad_fn=<SelectBackward0>)\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"aXrpMHhJ0aEW"},"execution_count":null,"outputs":[]}]}